'''
HYPERLIQUID'DEN ALABÄ°LECEÄÄ°NÄ°Z MAKSÄ°MUM VERÄ°  5000 MUM DUR.
DAHA FAZLASINA Ä°HTÄ°YACINIZ VARSA COINBASE SCRÄ°PTÄ°NÄ° KULLANIN
'''
import pandas as pd  
import requests      
from datetime import datetime, timedelta 
import numpy as np   
import time          
import sys
import os    
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'implement'))
import funcs_n as n

symbol = 'BTC'     # kripto para sembolÃ¼ 
timeframe = '15m'   # 1 gÃ¼nlÃ¼k mumlar


# BATCH_SIZE = 100000 # HYPERLIQUID Ä°Ã‡Ä°N MAKSÄ°MUM 5000, DAHA FAZLASI Ä°Ã‡Ä°N COINBASE KULLANIN
#                  # tek bir API isteÄŸinde alÄ±nacak maksimum mum sayÄ±sÄ±
# MAX_RETRIES = 3   # baÅŸarÄ±sÄ±z bir API isteÄŸi iÃ§in maksimum yeniden deneme sayÄ±sÄ±
# MAX_ROWS = 1000000   # sonuÃ§ta elde edilecek maksimum satÄ±r sayÄ±sÄ±nÄ± sÄ±nÄ±rlamak iÃ§in yeni bir sabit

# # Zaman damgasÄ± farkÄ±nÄ± saklamak iÃ§in global deÄŸiÅŸken
# timestamp_offset = None # API'den gelen zaman damgalarÄ±ndaki olasÄ± bir hatayÄ± dÃ¼zeltmek iÃ§in kullanÄ±lacak fark

# def adjust_timestamp(dt):
#     # Bu fonksiyon, API'den gelen zaman damgalarÄ±nÄ± dÃ¼zeltir.
#     if timestamp_offset is not None: # EÄŸer bir fark hesaplanmÄ±ÅŸsa
#         corrected_dt = dt - timestamp_offset  #zaman damgasÄ±nÄ± dÃ¼zelt
#         return corrected_dt
#     else:
#         return dt  

# def get_ohlcv2(symbol, interval, start_time, end_time, batch_size=BATCH_SIZE):
#     # Bu fonksiyon Hyperliquid API'sinden OHLCV verilerini Ã§eker.
#     global timestamp_offset 
#     print(f'\nğŸ” Veri talep ediliyor:')
#     print(f'ğŸ“Š Parti Boyutu (Batch Size): {batch_size}')
#     print(f'ğŸš€ BaÅŸlangÄ±Ã§: {start_time.strftime("%Y-%m-%d %H:%M:%S")} UTC') 
#     print(f'ğŸ¯ BitiÅŸ: {end_time.strftime("%Y-%m-%d %H:%M:%S")} UTC')  

#     # milisaniye cinsinden zamana Ã§evir
#     start_ts = int(start_time.timestamp() * 1000)
#     end_ts = int(end_time.timestamp() * 1000)

#     # API isteÄŸini en fazla MAX_RETRIES kadar dene
#     for attempt in range(MAX_RETRIES):
#         try:
#             # Hyperliquid API'sine POST isteÄŸi gÃ¶nder
#             response = requests.post(
#                 'https://api.hyperliquid.xyz/info', 
#                 headers={'Content-Type': 'application/json'}, # Ä°stek baÅŸlÄ±ÄŸÄ±
#                 json={ # JSON formatÄ±nda istek gÃ¶vdesi
#                     "type": "candleSnapshot", # mum verisi istendiÄŸini belirtir
#                     "req": {
#                         "coin": symbol,        # Sembol 
#                         "interval": interval,  # Zaman aralÄ±ÄŸÄ± 
#                         "startTime": start_ts, # BaÅŸlangÄ±Ã§ zaman damgasÄ±
#                         "endTime": end_ts,     # BitiÅŸ zaman damgasÄ±
#                         "limit": batch_size    # Ä°stenen maksimum mum sayÄ±sÄ±
#                     }
#                 },
#                 timeout=10 
#             )

#             if response.status_code == 200: # Ä°stek baÅŸarÄ±lÄ±ysa (HTTP 200 OK)
#                 print("veriler Ã§ekiliyor")
#                 snapshot_data = response.json() 
#                 if snapshot_data: # API'den veri dÃ¶ndÃ¼yse
#                     if timestamp_offset is None:
#                         latest_api_timestamp = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
#                         # Sisteminizin ÅŸu anki tarihi (kendi gÃ¼ncel tarihinize gÃ¶re ayarlayÄ±n)
#                         system_current_date = datetime.utcnow()
#                         # Beklenen en son zaman damgasÄ±nÄ± manuel olarak ayarla (Ã¶rn: ÅŸimdi)
#                         expected_latest_timestamp = system_current_date
                        
#                         timestamp_offset = latest_api_timestamp - expected_latest_timestamp
#                         print(f"â±ï¸ Hesaplanan zaman damgasÄ± farkÄ±: {timestamp_offset}")

#                     # API hatasÄ± nedeniyle zaman damgalarÄ±nÄ± ayarla
#                     for candle in snapshot_data:
#                         dt = datetime.utcfromtimestamp(candle['t'] / 1000) # Mumun zaman damgasÄ±nÄ± datetime nesnesine Ã§evir
#                         # Tarihi ayarla
#                         adjusted_dt = adjust_timestamp(dt) # adjust_timestamp fonksiyonu ile dÃ¼zelt
#                         candle['t'] = int(adjusted_dt.timestamp() * 1000) # DÃ¼zeltilmiÅŸ zamanÄ± tekrar milisaniye cinsinden ata

#                     # AlÄ±nan verinin ilk ve son zaman damgalarÄ±nÄ± yazdÄ±r (dÃ¼zeltilmiÅŸ)
#                     first_time = datetime.utcfromtimestamp(snapshot_data[0]['t'] / 1000)
#                     last_time = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
#                     print(f'âœ¨ {len(snapshot_data)} adet mum alÄ±ndÄ±')
#                     print(f'ğŸ“ˆ Ä°lk: {first_time}')
#                     print(f'ğŸ“‰ Son: {last_time}')
#                     return snapshot_data # AlÄ±nan veriyi (mum listesi) dÃ¶ndÃ¼r
#                 else:
#                     print('âŒ API tarafÄ±ndan veri dÃ¶ndÃ¼rÃ¼lmedi')
#                     return None # Veri yoksa None dÃ¶ndÃ¼r
#             else: # HTTP hatasÄ± varsa
#                 print(f'âš ï¸ HTTP HatasÄ± {response.status_code}: {response.text}')
#         except requests.exceptions.RequestException as e: # Ä°stek sÄ±rasÄ±nda bir hata oluÅŸursa
#             print(f'âš ï¸ Ä°stek baÅŸarÄ±sÄ±z oldu (deneme {attempt + 1}): {e}')
#             time.sleep(1) # 1 saniye bekle ve tekrar dene
#     return None # TÃ¼m denemeler baÅŸarÄ±sÄ±z olursa None dÃ¶ndÃ¼r

# def process_data_to_df(snapshot_data):
#     # Bu fonksiyon, API'den gelen ham veriyi pandas dataFrameine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
#     if snapshot_data: 
#         columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume'] 
#         data = [] 
#         for snapshot in snapshot_data: 
#             # Verileri ilgili deÄŸiÅŸkenlere ata
#             timestamp = datetime.utcfromtimestamp(snapshot['t'] / 1000)
#             open_price = snapshot['o'] 
#             high_price = snapshot['h'] 
#             low_price = snapshot['l'] 
#             close_price = snapshot['c'] 
#             volume = snapshot['v'] 
#             data.append([timestamp, open_price, high_price, low_price, close_price, volume]) 

#         df = pd.DataFrame(data, columns=columns) 
#         return df
#     else:
#         return pd.DataFrame() 

# def fetch_historical_data(symbol, timeframe):
#     """5000 satÄ±r geÃ§miÅŸ veri Ã§eker."""
#     # Bu ana fonksiyon, veri Ã§ekme iÅŸlemini yÃ¶netir.
#     print("\nğŸŒ™ GeÃ§miÅŸ Veri Ã‡ekici")
#     print(f"ğŸ¯ Sembol: {symbol}")
#     print(f"â° Zaman AralÄ±ÄŸÄ±: {timeframe}")

#     # Sadece en son 5000 mumu Ã§ek
#     end_time = datetime.utcnow() # BitiÅŸ zamanÄ± olarak ÅŸu anki UTC zamanÄ±nÄ± al
#     # GeniÅŸ bir zaman aralÄ±ÄŸÄ± belirleyerek yeterli veri almayÄ± hedefler.
#     # API tek seferde 5000 mum getireceÄŸi iÃ§in, bu aralÄ±k 5000 mumu kapsayacak kadar geniÅŸ olmalÄ±.
#     start_time = end_time - timedelta(days=5000) # Ã–rnek olarak son 60 gÃ¼nÃ¼ kapsayan bir baÅŸlangÄ±Ã§ zamanÄ±

#     print("\nğŸ”„ Veri Ã§ekiliyor:")
#     print(f"ğŸ“… BaÅŸlangÄ±Ã§: {start_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
#     print(f"ğŸ“… BitiÅŸ: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")

#     # get_ohlcv2 fonksiyonunu kullanarak veriyi Ã§ek
#     # batch_size=5000 ile tek bir istekte maksimum mumu almayÄ± hedefler.

#     #data = get_ohlcv2(symbol, timeframe, start_time, end_time, batch_size=5000)
#     data = n.get_historical_data_iterative(symbol, timeframe, 10000)

    
    
#     if data.empty: 
#         print("âŒ Veri mevcut deÄŸil.")
#         return pd.DataFrame() 

#     # Ã‡ekilen ham veriyi DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
#     df = process_data_to_df(data)

#     if not df.empty: # DataFrame boÅŸ deÄŸilse
#         # Zaman damgasÄ±na gÃ¶re sÄ±rala ve en son 5000 satÄ±rÄ± al, sonra tekrar zaman damgasÄ±na gÃ¶re sÄ±rala
        
#         df = df.sort_values('timestamp', ascending=False).head(5000).sort_values('timestamp')
#         df = df.reset_index(drop=True) # DataFrame indeksini sÄ±fÄ±rla

#         print("\nğŸ“Š Nihai veri Ã¶zeti:")
#         print(f"ğŸ“ˆ Toplam mum sayÄ±sÄ±: {len(df)}")
#         print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['timestamp'].min()} ile {df['timestamp'].max()}")
        

#     return df 


# # fetch_historical_data fonksiyonunu Ã§aÄŸÄ±rarak BTC iÃ§in 1 gÃ¼nlÃ¼k verileri Ã§ek
# all_data = fetch_historical_data(symbol, timeframe)

# # Veriyi kaydet
# if not all_data.empty: # EÄŸer veri baÅŸarÄ±yla Ã§ekildiyse
#     # Dosya adÄ± iÃ§in ÅŸu anki UTC zaman damgasÄ±nÄ± oluÅŸtur
#     timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
#     # Mevcut klasÃ¶re doÄŸrudan kaydetmek iÃ§in gÃ¼ncellenmiÅŸ yol
#     file_path = f'C:/masaustu/basicAlgoTrade/backtest/data/guncel{symbol}_{timeframe}_{timestamp}_historical.csv' # kendi klasor yolunuz
#     all_data.to_csv(file_path, index=False) # DataFrame'i CSV dosyasÄ±na kaydet (indeks olmadan)
#     print(f'\nğŸ’¾ Veri {file_path} adresine kaydedildi ğŸš€')
# else: 
#     print('âŒ  Kaydedilecek veri yok. Daha sonra tekrar deneyin! ğŸŒ™')
'''
HYPERLIQUID'DEN ALABÄ°LECEÄÄ°NÄ°Z MAKSÄ°MUM VERÄ°  5000 MUM DUR.
DAHA FAZLASINA Ä°HTÄ°YACINIZ VARSA COINBASE SCRÄ°PTÄ°NÄ° KULLANIN
'''
import pandas as pd
# requests artÄ±k burada doÄŸrudan kullanÄ±lmÄ±yor, funcs_n iÃ§inde
from datetime import datetime, timedelta
# numpy ve time artÄ±k burada doÄŸrudan kullanÄ±lmÄ±yor gibi, funcs_n iÃ§inde olabilir
import sys
import os

# --- nice_funcs (funcs_n) import kÄ±smÄ± ---
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'implement'))
try:
    import funcs_n as n
    # print(f"'funcs_n.py' baÅŸarÄ±yla import edildi.") # Bu satÄ±rÄ± test sonrasÄ± kaldÄ±rabilirsiniz
except ImportError as e:
    print(f"Hata: 'implement' klasÃ¶rÃ¼nden modÃ¼l import edilemedi. {e}")
    exit()
# --- Bitti: nice_funcs (funcs_n) import kÄ±smÄ± ---

symbol = 'BTC'
timeframe = '15m'
TOTAL_CANDLES_TO_FETCH = 10000 # funcs_n.get_historical_data_iterative'e geÃ§ilecek mum sayÄ±sÄ±

# ----- BU FONKSÄ°YONLARA ARTIK data.py Ä°Ã‡Ä°NDE Ä°HTÄ°YAÃ‡ YOK (funcs_n.py'de benzerleri var veya iÅŸlevleri deÄŸiÅŸti) -----
# def adjust_timestamp(dt):
#     ...
# def get_ohlcv2(symbol, interval, start_time, end_time, batch_size=BATCH_SIZE):
#     ...
# def process_data_to_df(snapshot_data): # <<<--- BU FONKSÄ°YONU TAMAMEN SÄ°LÄ°N VEYA YORUM YAPIN
#     # if snapshot_data: # BURASI DataFrame ile Ã§aÄŸrÄ±ldÄ±ÄŸÄ± iÃ§in HATA VERÄ°YORDU
#     #     ...
#     # else:
#     #     return pd.DataFrame()
# ----- Bitti: Ä°HTÄ°YAÃ‡ OLMAYAN FONKSÄ°YONLAR -----


def fetch_historical_data_from_source(symbol_param, timeframe_param, num_candles_to_get): # Fonksiyon adÄ±nÄ± deÄŸiÅŸtirdim, daha aÃ§Ä±klayÄ±cÄ±
    """
    Belirtilen kaynaktan (ÅŸu anda funcs_n aracÄ±lÄ±ÄŸÄ±yla Hyperliquid)
    geÃ§miÅŸ mum verilerini Ã§eker.
    """
    print("\nğŸŒ™ GeÃ§miÅŸ Veri Ã‡ekici (funcs_n Ã¼zerinden)")
    print(f"ğŸ¯ Sembol: {symbol_param}")
    print(f"â° Zaman AralÄ±ÄŸÄ±: {timeframe_param}")
    print(f"ğŸ”¢ Ä°stenen Mum SayÄ±sÄ±: {num_candles_to_get}")

    # DoÄŸrudan funcs_n'den DataFrame'i al
    df = n.get_historical_data_iterative(symbol_param, timeframe_param, num_candles_to_get)

    if df.empty:
        print("âŒ Veri mevcut deÄŸil veya funcs_n.get_historical_data_iterative'den boÅŸ DataFrame dÃ¶ndÃ¼.")
        return pd.DataFrame() # BoÅŸ DataFrame dÃ¶ndÃ¼r

    # process_data_to_df Ã§aÄŸrÄ±sÄ± ARTIK YOK. df zaten bir DataFrame.

    # EÄŸer burada Ã¶zellikle son X mumu almak gibi bir mantÄ±ÄŸÄ±nÄ±z varsa, onu burada yapabilirsiniz.
    # Ancak get_historical_data_iterative zaten total_candles_needed kadarÄ±nÄ± getirmeyi hedefliyor.
    # Ã–rneÄŸin, API 5000 limitine raÄŸmen 10000 istediysek ve funcs_n 10000 getirdiyse,
    # burada tekrar head(5000) yapmak veri kaybÄ±na neden olur.
    # Åimdilik bu kÄ±smÄ± yorumluyorum, Ã§Ã¼nkÃ¼ get_historical_data_iterative'in amacÄ± bu.
    #
    # if not df.empty:
    #     # df = df.sort_values('timestamp', ascending=False).head(5000).sort_values('timestamp')
    #     # df = df.reset_index(drop=True)
    #     print("\nğŸ“Š Nihai veri Ã¶zeti (iÅŸlem sonrasÄ±):") # Bu mesaj da yanÄ±ltÄ±cÄ± olabilir
    #     print(f"ğŸ“ˆ Toplam mum sayÄ±sÄ±: {len(df)}")
    #     if not df.empty:
    #          print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['timestamp'].min()} ile {df['timestamp'].max()}")

    return df


# --- Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu ---
if __name__ == "__main__": # Script doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda bu blok Ã§alÄ±ÅŸsÄ±n
    print('sup dawg') # Test mesajÄ±, kaldÄ±rÄ±labilir

    # fetch_historical_data_from_source fonksiyonunu Ã§aÄŸÄ±r
    all_data = fetch_historical_data_from_source(symbol, timeframe, TOTAL_CANDLES_TO_FETCH)

    if not all_data.empty:
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        save_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')
        if not os.path.exists(save_directory):
            os.makedirs(save_directory)
            print(f"'{save_directory}' klasÃ¶rÃ¼ oluÅŸturuldu.")

        file_name = f"guncel{symbol.replace('/', '_')}_{timeframe}_{timestamp_str}_historical.csv"
        file_path = os.path.join(save_directory, file_name)

        all_data.to_csv(file_path, index=False)
        print(f'\nğŸ’¾ Veri {file_path} adresine kaydedildi ğŸš€')
    else:
        print('âŒ Kaydedilecek veri yok. Daha sonra tekrar deneyin! ğŸŒ™')