'''
HYPERLIQUID'DEN ALABÄ°LECEÄÄ°NÄ°Z MAKSÄ°MUM VERÄ°  5000 MUM DUR.
DAHA FAZLASINA Ä°HTÄ°YACINIZ VARSA COINBASE SCRÄ°PTÄ°NÄ° KULLANIN
'''
import pandas as pd  
import requests      
from datetime import datetime, timedelta 
import numpy as np   
import time          
import os          


symbol = 'BTC'     # kripto para sembolÃ¼ 
timeframe = '1d'   # 1 gÃ¼nlÃ¼k mumlar


BATCH_SIZE = 5000 # HYPERLIQUID Ä°Ã‡Ä°N MAKSÄ°MUM 5000, DAHA FAZLASI Ä°Ã‡Ä°N COINBASE KULLANIN
                 # tek bir API isteÄŸinde alÄ±nacak maksimum mum sayÄ±sÄ±
MAX_RETRIES = 3   # baÅŸarÄ±sÄ±z bir API isteÄŸi iÃ§in maksimum yeniden deneme sayÄ±sÄ±
MAX_ROWS = 5000   # sonuÃ§ta elde edilecek maksimum satÄ±r sayÄ±sÄ±nÄ± sÄ±nÄ±rlamak iÃ§in yeni bir sabit

# Zaman damgasÄ± farkÄ±nÄ± saklamak iÃ§in global deÄŸiÅŸken
timestamp_offset = None # API'den gelen zaman damgalarÄ±ndaki olasÄ± bir hatayÄ± dÃ¼zeltmek iÃ§in kullanÄ±lacak fark

def adjust_timestamp(dt):
    # Bu fonksiyon, API'den gelen zaman damgalarÄ±nÄ± dÃ¼zeltir.
    if timestamp_offset is not None: # EÄŸer bir fark hesaplanmÄ±ÅŸsa
        corrected_dt = dt - timestamp_offset  #zaman damgasÄ±nÄ± dÃ¼zelt
        return corrected_dt
    else:
        return dt  

def get_ohlcv2(symbol, interval, start_time, end_time, batch_size=BATCH_SIZE):
    # Bu fonksiyon Hyperliquid API'sinden OHLCV verilerini Ã§eker.
    global timestamp_offset 
    print(f'\nğŸ” Veri talep ediliyor:')
    print(f'ğŸ“Š Parti Boyutu (Batch Size): {batch_size}')
    print(f'ğŸš€ BaÅŸlangÄ±Ã§: {start_time.strftime("%Y-%m-%d %H:%M:%S")} UTC') 
    print(f'ğŸ¯ BitiÅŸ: {end_time.strftime("%Y-%m-%d %H:%M:%S")} UTC')  

    # milisaniye cinsinden zamana Ã§evir
    start_ts = int(start_time.timestamp() * 1000)
    end_ts = int(end_time.timestamp() * 1000)

    # API isteÄŸini en fazla MAX_RETRIES kadar dene
    for attempt in range(MAX_RETRIES):
        try:
            # Hyperliquid API'sine POST isteÄŸi gÃ¶nder
            response = requests.post(
                'https://api.hyperliquid.xyz/info', 
                headers={'Content-Type': 'application/json'}, # Ä°stek baÅŸlÄ±ÄŸÄ±
                json={ # JSON formatÄ±nda istek gÃ¶vdesi
                    "type": "candleSnapshot", # mum verisi istendiÄŸini belirtir
                    "req": {
                        "coin": symbol,        # Sembol 
                        "interval": interval,  # Zaman aralÄ±ÄŸÄ± 
                        "startTime": start_ts, # BaÅŸlangÄ±Ã§ zaman damgasÄ±
                        "endTime": end_ts,     # BitiÅŸ zaman damgasÄ±
                        "limit": batch_size    # Ä°stenen maksimum mum sayÄ±sÄ±
                    }
                },
                timeout=10 
            )

            if response.status_code == 200: # Ä°stek baÅŸarÄ±lÄ±ysa (HTTP 200 OK)
                snapshot_data = response.json() 
                if snapshot_data: # API'den veri dÃ¶ndÃ¼yse
                    if timestamp_offset is None:
                        latest_api_timestamp = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
                        # Sisteminizin ÅŸu anki tarihi (kendi gÃ¼ncel tarihinize gÃ¶re ayarlayÄ±n)
                        system_current_date = datetime.utcnow()
                        # Beklenen en son zaman damgasÄ±nÄ± manuel olarak ayarla (Ã¶rn: ÅŸimdi)
                        expected_latest_timestamp = system_current_date
                        
                        timestamp_offset = latest_api_timestamp - expected_latest_timestamp
                        print(f"â±ï¸ Hesaplanan zaman damgasÄ± farkÄ±: {timestamp_offset}")

                    # API hatasÄ± nedeniyle zaman damgalarÄ±nÄ± ayarla
                    for candle in snapshot_data:
                        dt = datetime.utcfromtimestamp(candle['t'] / 1000) # Mumun zaman damgasÄ±nÄ± datetime nesnesine Ã§evir
                        # Tarihi ayarla
                        adjusted_dt = adjust_timestamp(dt) # adjust_timestamp fonksiyonu ile dÃ¼zelt
                        candle['t'] = int(adjusted_dt.timestamp() * 1000) # DÃ¼zeltilmiÅŸ zamanÄ± tekrar milisaniye cinsinden ata

                    # AlÄ±nan verinin ilk ve son zaman damgalarÄ±nÄ± yazdÄ±r (dÃ¼zeltilmiÅŸ)
                    first_time = datetime.utcfromtimestamp(snapshot_data[0]['t'] / 1000)
                    last_time = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
                    print(f'âœ¨ {len(snapshot_data)} adet mum alÄ±ndÄ±')
                    print(f'ğŸ“ˆ Ä°lk: {first_time}')
                    print(f'ğŸ“‰ Son: {last_time}')
                    return snapshot_data # AlÄ±nan veriyi (mum listesi) dÃ¶ndÃ¼r
                else:
                    print('âŒ API tarafÄ±ndan veri dÃ¶ndÃ¼rÃ¼lmedi')
                    return None # Veri yoksa None dÃ¶ndÃ¼r
            else: # HTTP hatasÄ± varsa
                print(f'âš ï¸ HTTP HatasÄ± {response.status_code}: {response.text}')
        except requests.exceptions.RequestException as e: # Ä°stek sÄ±rasÄ±nda bir hata oluÅŸursa
            print(f'âš ï¸ Ä°stek baÅŸarÄ±sÄ±z oldu (deneme {attempt + 1}): {e}')
            time.sleep(1) # 1 saniye bekle ve tekrar dene
    return None # TÃ¼m denemeler baÅŸarÄ±sÄ±z olursa None dÃ¶ndÃ¼r

def process_data_to_df(snapshot_data):
    # Bu fonksiyon, API'den gelen ham veriyi pandas dataFrameine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    if snapshot_data: 
        columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume'] 
        data = [] 
        for snapshot in snapshot_data: 
            # Verileri ilgili deÄŸiÅŸkenlere ata
            timestamp = datetime.utcfromtimestamp(snapshot['t'] / 1000)
            open_price = snapshot['o'] 
            high_price = snapshot['h'] 
            low_price = snapshot['l'] 
            close_price = snapshot['c'] 
            volume = snapshot['v'] 
            data.append([timestamp, open_price, high_price, low_price, close_price, volume]) 

        df = pd.DataFrame(data, columns=columns) 
        return df
    else:
        return pd.DataFrame() 

def fetch_historical_data(symbol, timeframe):
    """5000 satÄ±r geÃ§miÅŸ veri Ã§eker."""
    # Bu ana fonksiyon, veri Ã§ekme iÅŸlemini yÃ¶netir.
    print("\nğŸŒ™ GeÃ§miÅŸ Veri Ã‡ekici")
    print(f"ğŸ¯ Sembol: {symbol}")
    print(f"â° Zaman AralÄ±ÄŸÄ±: {timeframe}")

    # Sadece en son 5000 mumu Ã§ek
    end_time = datetime.utcnow() # BitiÅŸ zamanÄ± olarak ÅŸu anki UTC zamanÄ±nÄ± al
    # GeniÅŸ bir zaman aralÄ±ÄŸÄ± belirleyerek yeterli veri almayÄ± hedefler.
    # API tek seferde 5000 mum getireceÄŸi iÃ§in, bu aralÄ±k 5000 mumu kapsayacak kadar geniÅŸ olmalÄ±.
    start_time = end_time - timedelta(days=60) # Ã–rnek olarak son 60 gÃ¼nÃ¼ kapsayan bir baÅŸlangÄ±Ã§ zamanÄ±

    print("\nğŸ”„ Veri Ã§ekiliyor:")
    print(f"ğŸ“… BaÅŸlangÄ±Ã§: {start_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
    print(f"ğŸ“… BitiÅŸ: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")

    # get_ohlcv2 fonksiyonunu kullanarak veriyi Ã§ek
    # batch_size=5000 ile tek bir istekte maksimum mumu almayÄ± hedefler.
    data = get_ohlcv2(symbol, timeframe, start_time, end_time, batch_size=5000)
    
    if not data: 
        print("âŒ Veri mevcut deÄŸil.")
        return pd.DataFrame() 

    # Ã‡ekilen ham veriyi DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
    df = process_data_to_df(data)

    if not df.empty: # DataFrame boÅŸ deÄŸilse
        # Zaman damgasÄ±na gÃ¶re sÄ±rala ve en son 5000 satÄ±rÄ± al, sonra tekrar zaman damgasÄ±na gÃ¶re sÄ±rala
        
        df = df.sort_values('timestamp', ascending=False).head(5000).sort_values('timestamp')
        df = df.reset_index(drop=True) # DataFrame indeksini sÄ±fÄ±rla

        print("\nğŸ“Š Nihai veri Ã¶zeti:")
        print(f"ğŸ“ˆ Toplam mum sayÄ±sÄ±: {len(df)}")
        print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['timestamp'].min()} ile {df['timestamp'].max()}")
        

    return df 


# fetch_historical_data fonksiyonunu Ã§aÄŸÄ±rarak BTC iÃ§in 1 gÃ¼nlÃ¼k verileri Ã§ek
all_data = fetch_historical_data(symbol, timeframe)

# Veriyi kaydet
if not all_data.empty: # EÄŸer veri baÅŸarÄ±yla Ã§ekildiyse
    # Dosya adÄ± iÃ§in ÅŸu anki UTC zaman damgasÄ±nÄ± oluÅŸtur
    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
    # Mevcut klasÃ¶re doÄŸrudan kaydetmek iÃ§in gÃ¼ncellenmiÅŸ yol
    file_path = f'C:/masaustu/basicAlgoTrade/backtest/data/{symbol}_{timeframe}_{timestamp}_historical.csv' # kendi klasor yolunuz
    all_data.to_csv(file_path, index=False) # DataFrame'i CSV dosyasÄ±na kaydet (indeks olmadan)
    print(f'\nğŸ’¾ Veri {file_path} adresine kaydedildi ğŸš€')
else: 
    print('âŒ  Kaydedilecek veri yok. Daha sonra tekrar deneyin! ğŸŒ™')